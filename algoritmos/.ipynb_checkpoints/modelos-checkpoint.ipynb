{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importando as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, pi, sqrt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Modelos\n",
    "\n",
    "##### 2.1 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que computa a função logística (sigmóide)\n",
    "def sigmoide(row, w):\n",
    "    yPred = 1/(1+np.exp(-row @ w))\n",
    "    return yPred\n",
    "\n",
    "# Função responsável para treinar o modelo de Regressão Logística via Gradiente Descendente\n",
    "def fitRL(x, y, n_epochs, alpha):\n",
    "    erroQM = []\n",
    "    wPrev = np.zeros(x.shape[1]+1)\n",
    "    aux = np.ones((x.shape[0], 1))\n",
    "    x = np.hstack((aux, x))\n",
    "    \n",
    "    for epochs in range (0,n_epochs):\n",
    "        suma = 0\n",
    "        sumErro = 0\n",
    "        for i in range(0, x.shape[0]):\n",
    "            sumErro = sumErro + (y[i]-sigmoide(x[i],wPrev))**2\n",
    "            suma = suma +  (y[i]-sigmoide(x[i],wPrev))*np.transpose(x[i])\n",
    "        w = np.transpose(wPrev) + alpha*(1/x.shape[0])*suma\n",
    "        erroEp = ((1/(2*x.shape[0]))*sumErro)\n",
    "        erroQM.append(erroEp)\n",
    "        wPrev = w\n",
    "    return wPrev, erroQM\n",
    "\n",
    "# Função responsável para predizer os dados\n",
    "def predictRL(w, x):\n",
    "    yPredito = []\n",
    "    aux = np.ones((x.shape[0], 1))\n",
    "    x = np.hstack((aux, x))\n",
    "    for row in x:\n",
    "        if(sigmoide(row, w)>=0.5):\n",
    "            yPredito.append(1)\n",
    "        else:\n",
    "            yPredito.append(0)\n",
    "    return yPredito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Análise de Discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável para \"treinar\" que gera os dados estatísticos necessários para o modelo de \n",
    "# Análise de Discriminante Gaussiano\n",
    "def fitAGD(x, y):\n",
    "    classes, ocorrencs = np.unique(y, return_counts=True) # pegando as classes e ocorrencias\n",
    "    numClasses = len(classes) # numero de classes\n",
    "    n = len(y) # numero de linhas do dataset\n",
    "    numFeatures = x.shape[1] # numero de colunas do dataset\n",
    "    \n",
    "    # Probabilidade das classes será proporcional a frequencia dessa classe no dataset\n",
    "    probabilidadeClasses = dict(zip(classes, ocorrencs))\n",
    "    for key in probabilidadeClasses:\n",
    "        probabilidadeClasses[key] = probabilidadeClasses[key] / n\n",
    "    \n",
    "    media = np.zeros((numFeatures, numClasses)) # criando a lista da media das features por classe\n",
    "    covar = np.zeros((numFeatures, numFeatures, numClasses)) # criando a lista de matrizes de correlação das features para cada classe\n",
    "\n",
    "    for classe in classes:\n",
    "        xk = x[y == classe] # pega as linhas em que classe é igual ao y -> que aí eu acesso essas linhas do x\n",
    "        classe = int(classe)\n",
    "        media[:, int(classe)] = np.mean(xk, axis=0)\n",
    "        xi_mean = xk - media[:, int(classe)]\n",
    "        covar[:, :, int(classe)] = (np.transpose(xi_mean) @ xi_mean)/len(xk)\n",
    "        covar[:, :, int(classe)] += np.eye(numFeatures) * np.mean(np.diag(covar[:,:,classe]))  * 10 ** -6 # ver se assim ta certo, pq o do cesar ele botou uns numeros que eu nao entendi\n",
    "    return {'media': media, 'covar': covar, 'classes': classes, 'numRows': n, 'numClasses': numClasses, 'numFeatures': numFeatures, 'probabilidadeClasses': probabilidadeClasses }\n",
    "\n",
    "# Função responsável para predizer a classe de um único registro\n",
    "def predict1AGD(model, row):\n",
    "    probabilits = np.zeros(model['numClasses'])\n",
    "    for classe in model['classes']:\n",
    "        classe = int(classe)\n",
    "        fator1 = 1/(sqrt(np.linalg.det(model['covar'][:, :, classe])) * ((2*pi)**(model['numFeatures']/2)))\n",
    "        \n",
    "        inversa = np.linalg.inv(model['covar'][:, :, classe])\n",
    "        difXMedia = row - model['media'][:, classe]\n",
    "        z = (-0.5) * (np.transpose(difXMedia) @ inversa @ difXMedia) # valor que fica dentro do exp\n",
    "        probabilits[classe] = fator1 * np.exp(z)\n",
    "    return model['classes'][np.argmax(probabilits)]\n",
    "    \n",
    "# Função utilizada para predizer as classes de um conjunto de registros\n",
    "def predictAGD(model, x_test):\n",
    "    yPredito = np.array([predict1AGD(model, row) for row in x_test])\n",
    "    return yPredito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções que realizam os cálculos de distância entre dois registros\n",
    "def distance_euclidian(x1, x2):\n",
    "    return sqrt(np.sum([abs(i - j) for i, j in zip(x1,x2)]))\n",
    "\n",
    "def distance_manhattan(x1, x2):\n",
    "    return np.sum([abs(i-j) for i, j in zip(x1,x2)])\n",
    "\n",
    "def getClasses(y):\n",
    "    return pd.array(data[:,-1]).unique()\n",
    "\n",
    "# Função responsável por predizer a classe de um único registro\n",
    "def predict1KNN(x, y, x_teste, k, function):\n",
    "    classes = getClasses(y)\n",
    "    results = []\n",
    "    for i in range(0, x.shape[0]):\n",
    "        results.append([function(x[i], x_teste), y[i]])\n",
    "    results = sorted(results)\n",
    "    dictClasses = {}\n",
    "    for i in classes:\n",
    "        dictClasses[i] = 0\n",
    "    for i in range(0, k):\n",
    "        for row in dictClasses.keys():\n",
    "            if results[i][1] == row:\n",
    "                dictClasses[row] += 1\n",
    "    \n",
    "    # retornar a chave que tem maior contagem\n",
    "    minimus = [results[i][1] for i in range (0,k)]\n",
    "    \n",
    "    contClasses = [(x, minimus.count(x)) for x in set(minimus)]\n",
    "\n",
    "    maximo = np.argmax(contClasses, axis=0)\n",
    "    \n",
    "    return contClasses[maximo[1]][0]\n",
    "\n",
    "# Função utilizada para predizer as classes de um conjunto de registros\n",
    "def predictKNN(x, y, x_test, k, function):\n",
    "    yPredito = [predict1KNN(x, y, row, k, function) for row in x_test]\n",
    "    return yPredito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável por treinar a Árvore de Decisão e escolher os melhores hiperparâmetros por meio de grid-search\n",
    "def fitAD(x, y):\n",
    "    listMaxDepth = range(1, 50)\n",
    "    configTree = {'criterion':['gini','entropy'],'max_depth':listMaxDepth}\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), configTree)\n",
    "    clf.fit(x, y)\n",
    "    params = clf.best_params_\n",
    "    tree = DecisionTreeClassifier(criterion = params['criterion'], max_depth=params['max_depth'])\n",
    "    return tree\n",
    "\n",
    "# Função que prediz a classe de um conjunto ou um único registro\n",
    "def predictAD(tree, x, y, x_test):\n",
    "    tree.fit(x, y)   \n",
    "    yPredito = tree.predict(x_test)\n",
    "    return yPredito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável por treinar o SVM e escolher os melhores hiperparâmetros por meio de grid-search\n",
    "def fitSVM(x, y):\n",
    "    model = SVC(gamma='auto')\n",
    "    configSVM = [{'kernel': ['rbf'], 'C': 2 ** np.arange(-5.0, 16.0, 2),\n",
    "                                  'gamma': 2 ** np.arange(-15.0, 4.0, 2)},\n",
    "                  {'kernel': ['poly'], 'C': 2 ** np.arange(-5.0, 16.0, 2),\n",
    "                                    'degree': np.arange(2, 6)},\n",
    "                  {'kernel': ['linear'], 'C': 2 ** np.arange(-5.0, 16.0, 2)}]\n",
    "\n",
    "    clf = GridSearchCV(model, configSVM, n_jobs=-1)\n",
    "    clf.fit(x, y)\n",
    "    params = clf.best_params_\n",
    "    if(params['kernel']=='rbf'):\n",
    "        svm = SVC(kernel = params['kernel'], C = params['C'], gamma = params['gamma'])\n",
    "    if(params['kernel']=='poly'):\n",
    "        svm = SVC(gamma = 'auto', kernel = params['kernel'], C = params['C'], degree = params['degree'])\n",
    "    return svm\n",
    "\n",
    "# Função que prediz a classe de um conjunto ou um único registro\n",
    "def predictSVM(svm, x, y, x_test):\n",
    "    svm.fit(x, y)\n",
    "    yPredito = svm.predict(x)\n",
    "    return yPredito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável por treinar o Random Forest e escolher os melhores hiperparâmetros por meio de grid-search\n",
    "def fitRF(x, y):\n",
    "    listEstimators = range(100, 150)\n",
    "    listMaxDepth = range(1, 10)\n",
    "    configRandom = {'criterion':['gini','entropy'],'n_estimators':listEstimators, 'max_depth':listMaxDepth}\n",
    "    clf = GridSearchCV(RandomForestClassifier(), configRandom)\n",
    "    clf.fit(x,y)\n",
    "    params = clf.best_params_\n",
    "    randomForest = RandomForestClassifier(criterion = params['criterion'], max_depth=params['max_depth'], n_estimators=params['n_estimators'])\n",
    "    return randomForest\n",
    "\n",
    "# Função que prediz a classe de um conjunto ou um único registro\n",
    "def predictRF(randomForest, x, y, x_test):\n",
    "    randomForest.fit(x, y)\n",
    "    yPredito = randomForest.predict(x)\n",
    "    return yPredito"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
